{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPvW6YZ1asHv"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch pandas sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "fA8nJ6E7br-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load datasets (assuming they are uploaded to Colab or stored in Google Drive)\n",
        "# If in Google Drive, mount it:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "fake_df = pd.read_csv('/content/drive/MyDrive/ma_fake.csv')  # Adjust path as needed\n",
        "true_df = pd.read_csv('/content/drive/MyDrive/ma_true.csv')  # Adjust path as needed\n",
        "\n",
        "# Add labels\n",
        "fake_df['label'] = 0  # Fake news\n",
        "true_df['label'] = 1  # True news\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([fake_df, true_df], ignore_index=True)\n",
        "\n",
        "# Shuffle the dataset\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Basic preprocessing for Malayalam text\n",
        "def preprocess_text(text):\n",
        "    # Remove special characters, numbers, and extra spaces (adjust as needed for Malayalam)\n",
        "    text = str(text).strip()\n",
        "    text = ''.join(char for char in text if char.isalpha() or char.isspace() or char in 'അആഇഈഉഊഋഎഏഐഒഓൺം')\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)"
      ],
      "metadata": {
        "id": "BLtOeKAfbv4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "# Tokenize datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
      ],
      "metadata": {
        "id": "wAQ4QH_UcHhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,  # Increase epochs\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=200,  # Reduce warmup steps if dataset is small\n",
        "    weight_decay=0.1,  # Increase regularization\n",
        "    learning_rate=2e-5,  # Smaller learning rate for better convergence\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# Define compute_metrics function for evaluation\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds)\n",
        "    recall = recall_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "    }\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "CyCqXhwOcTTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"Evaluation results:\", eval_results)"
      ],
      "metadata": {
        "id": "ThA1mjo4e6PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model and tokenizer\n",
        "model.save_pretrained('/content/drive/MyDrive/lastdance')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/lastdance')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw2WC0zFgGx-",
        "outputId": "1dcaf28e-387e-4f1f-a134-0a62aa54daea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/lastdance/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/lastdance/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/lastdance/vocab.txt',\n",
              " '/content/drive/MyDrive/lastdance/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/lastdance')\n",
        "tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/lastdance')\n",
        "\n",
        "# Function to predict on new text\n",
        "def predict_fake_news(text):\n",
        "    # Preprocess and tokenize the text\n",
        "    text = preprocess_text(text)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "\n",
        "    # Make prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        prediction = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    return \"True\" if prediction == 1 else \"Fake\"\n",
        "# Example usage\n",
        "new_text = \"2000 രൂപ നോട്ടിന്റെ വിതരണം നിര്‍ത്തി റിസര്‍വ് ബാങ്ക്\"  # Replace with your Malayalam text\n",
        "result = predict_fake_news(new_text)\n",
        "print(f\"The text is predicted to be: {result}\")\n",
        "# Example usage\n",
        "new_text = \"'യുഡിഎഫ് കള്ളം പ്രചരിപ്പിക്കാറില്ല, ഉള്ളത് മാത്രമേ പറയു' പിണറായി വിജയൻ ഇങ്ങനെ പറഞ്ഞോ?...\"  # Replace with your Malayalam text\n",
        "result = predict_fake_news(new_text)\n",
        "print(f\"The text is predicted to be: {result}\")"
      ],
      "metadata": {
        "id": "9Ii6TEjzgWw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(labels, preds, target_names=['True', 'Fake']))"
      ],
      "metadata": {
        "id": "DhE_zn2vUcOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_fake_news(text):\n",
        "    text = preprocess_text(text)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        prediction = torch.argmax(logits, dim=1).item()\n",
        "    return \"True\" if prediction == 1 else \"Fake\"  # Swap if necessary"
      ],
      "metadata": {
        "id": "hKgOGhdAVO3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "new_text = \"മോദി ലോകത്തിൻ്റെ പ്രതീക്ഷ  പ്രധാനമന്ത്രിയെ പുകഴ്ത്തിയ ന്യൂ യോർക്ക് ടൈംസ് വാർത്ത വ്യാജമോ?\"  # Replace with your Malayalam text\n",
        "result = predict_fake_news(new_text)\n",
        "print(f\"The text is predicted to be: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwQtbDdZVRb_",
        "outputId": "d6db1300-d3e8-44a6-dc49-e3b266a4b795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text is predicted to be: Fake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "new_text = \"പത്മഭൂഷണ്‍ പുരസ്‌കാരം ഏറ്റുവാങ്ങി മോഹന്‍ലാല്‍.\"  # Replace with your Malayalam text\n",
        "result = predict_fake_news(new_text)\n",
        "print(f\"The text is predicted to be: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-aTusNuVj5Y",
        "outputId": "94c48819-da48-46ee-a504-987f26e3d113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text is predicted to be: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1oz_WJWud0iH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}